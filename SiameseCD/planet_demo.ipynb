{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f84244-7b34-4c6c-9523-865081f4e528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/proxy/8787/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 00:34:09,972 - distributed.diskutils - INFO - Found stale lock file and directory '/home/dylan/code/planet-regrid-poc/SiameseCD/dask-worker-space/worker-h5mnnbsg', purging\n",
      "2022-06-06 00:34:09,973 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "import utils\n",
    "import torch\n",
    "from models.basic_model import CDEvaluator\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import TypedDict\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "from rasterio.enums import Resampling\n",
    "import glob\n",
    "import certifi\n",
    "import pyproj\n",
    "import pystac\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "cluster = LocalCUDACluster(threads_per_worker=4)\n",
    "client = Client(cluster)\n",
    "print(f\"/proxy/{client.scheduler_info()['services']['dashboard']}/status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8fd39d-b74d-4db1-8a7c-73e94906efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    # ------------\n",
    "    # args\n",
    "    # ------------\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--project_name', default='BIT_LEVIR', type=str)\n",
    "    parser.add_argument('--gpu_ids', type=str, default='0', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n",
    "    parser.add_argument('--checkpoint_root', default='checkpoints', type=str)\n",
    "    parser.add_argument('--output_folder', default='samples/predict', type=str)\n",
    "\n",
    "    # data\n",
    "    parser.add_argument('--num_workers', default=0, type=int)\n",
    "    parser.add_argument('--dataset', default='CDDataset', type=str)\n",
    "    parser.add_argument('--data_name', default='quick_start', type=str)\n",
    "\n",
    "    parser.add_argument('--batch_size', default=1, type=int)\n",
    "    parser.add_argument('--split', default=\"demo\", type=str)\n",
    "    parser.add_argument('--img_size', default=256, type=int)\n",
    "\n",
    "    # model\n",
    "    parser.add_argument('--n_class', default=2, type=int)\n",
    "    parser.add_argument('--net_G', default='base_transformer_pos_s4_dd8_dedim8', type=str,\n",
    "                        help='base_resnet18 | base_transformer_pos_s4_dd8 | base_transformer_pos_s4_dd8_dedim8|')\n",
    "    parser.add_argument('--checkpoint_name', default='best_ckpt.pt', type=str)\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d67317-43d2-467b-91f8-1366c7a5337d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    args = get_args()\n",
    "    # device = torch.device(\"cuda:%s\" % args.gpu_ids[0]\n",
    "                          # if torch.cuda.is_available() and len(args.gpu_ids)>0\n",
    "                        # else \"cpu\")\n",
    "    # args.checkpoint_dir = os.path.join(args.checkpoint_root, args.project_name)\n",
    "    # os.makedirs(args.output_folder, exist_ok=True)\n",
    "\n",
    "    # log_path = os.path.join(args.output_folder, 'log_vis.txt')\n",
    "\n",
    "    # data_loader = utils.get_loader(args.data_name, img_size=args.img_size,\n",
    "    #                                batch_size=args.batch_size,\n",
    "    #                                split=args.split, is_train=False)\n",
    "\n",
    "    model = CDEvaluator(args)\n",
    "    model.load_checkpoint(args.checkpoint_name) \n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef86f00-ea08-4eb6-8e9a-51c6b86943db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: pending, key: load_model-b9b60b69a4cfb6fd8005b0956b529b7f>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 00:35:47,326 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       load_model-b9b60b69a4cfb6fd8005b0956b529b7f\n",
      "Function:  load_model\n",
      "args:      ()\n",
      "kwargs:    {}\n",
      "Exception: 'AttributeError(\"\\'Namespace\\' object has no attribute \\'checkpoint_dir\\'\")'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remote_model = client.submit(load_model)\n",
    "print(remote_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6b0b7-7b3a-4034-88cc-30c9094d01fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Planet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03bc41c-927f-431f-8a00-6926b17dcd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['PROJ_LIB'] = '/opt/conda/bin/proj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84795a72-e644-4fea-884c-61c34633a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rio.vrt.WarpedVRT(rio.open('./catalogs/21_05/mosaic.tif'))\n",
    "b = rio.vrt.WarpedVRT(rio.open('./catalogs/22_05/mosaic/mosaic.tif'),transform=a.transform,height=a.height,width=a.width)\n",
    "\n",
    "ds1 = rxr.open_rasterio(a,chunks=(4,8192,8192),lock=False)\n",
    "ds2 = rxr.open_rasterio(b,chunks=(4,8192,8192),lock=False)#'./catalogs/22_05/mosaic/mosaic.tif'\n",
    "\n",
    "# upscale_factor = 3\n",
    "# w_ds1 = ds1.rio.width*upscale_factor\n",
    "# h_ds1 = ds1.rio.height*upscale_factor\n",
    "# w_ds2 = ds2.rio.width*upscale_factor\n",
    "# h_ds2 = ds2.rio.height*upscale_factor\n",
    "\n",
    "# ds1 = ds1.rio.reproject(ds1.rio.crs,\n",
    "#                         shape=(h_ds1,w_ds1),\n",
    "#                         resampling=Resampling.bilinear,\n",
    "#                        )\n",
    "\n",
    "# ds2 = ds2.rio.reproject(ds2.rio.crs,\n",
    "#                         shape=(h_ds2,w_ds2),\n",
    "#                         resampling=Resampling.bilinear,\n",
    "#                        )\n",
    "\n",
    "ds1 = ds1[:3]\n",
    "ds2 = ds2[:3]\n",
    "\n",
    "ds1 = ds1/255.0\n",
    "ds2 = ds2/255.0\n",
    "\n",
    "# m1 = ds1.mean(axis=[1,2])\n",
    "# s1 = ds1.std(axis=[1,2])\n",
    "# m2 = ds2.mean(axis=[1,2])\n",
    "# s2 = ds2.std(axis=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7888eb-3942-4c80-bd8a-4ec74d79d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.combine_nested([ds1,ds2],concat_dim=\"time\").chunk((2,3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb30db-f91d-4f50-aa94-2807ea6a43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = xr.DataArray([1,2,3],name=\"band\",dims=[\"band\"],coords={\"band\":[1,2,3]})\n",
    "first_mu = xr.DataArray(np.array([0.5,0.5,0.5],dtype=\"float32\"),name=\"mean\",coords=[bands])\n",
    "second_mu = xr.DataArray(np.array([0.5,0.5,0.5],dtype=\"float32\"),name=\"mean\",coords=[bands])\n",
    "first_std = xr.DataArray(np.array([0.5,0.5,0.5],dtype=\"float32\"),name=\"std\",coords=[bands])\n",
    "second_std = xr.DataArray(np.array([0.5,0.5,0.5],dtype=\"float32\"),name=\"std\",coords=[bands])\n",
    "# first_mu = xr.DataArray(m1.data,name=\"mean\",coords=[bands])\n",
    "# first_std = xr.DataArray(s1.data,name=\"std\",coords=[bands])\n",
    "# second_mu = xr.DataArray(m2.data,name=\"mean\",coords=[bands])\n",
    "# second_std = xr.DataArray(s2.data,name=\"std\",coords=[bands])\n",
    "\n",
    "mean = xr.concat([first_mu,second_mu],dim=\"time\")\n",
    "std = xr.concat([first_std,second_std],dim=\"time\")\n",
    "\n",
    "# ds = ds/255.0\n",
    "normalized = (ds-mean)/std\n",
    "\n",
    "normalized = normalized.chunk((2,3,256,256))\n",
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dfa6ed-ff90-4cb4-bd1a-b82f68f31986",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = {}\n",
    "for coord in [\"y\",\"x\"]:\n",
    "    remainder = len(ds.coords[coord])%32\n",
    "    slice_ = slice(-remainder) if remainder else slice(None)\n",
    "    slices[coord] = slice_\n",
    "\n",
    "ds_comb = normalized.isel(**slices)\n",
    "\n",
    "ds_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7bb5d0-6a04-4f3d-a43b-67f7c362d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array\n",
    "def predict_chips(data,model)->torch.Tensor:\n",
    "    result = model._forward_pass(data).cpu().numpy()[0][0]\n",
    "    return result\n",
    "\n",
    "def copy_and_predict_chunked(tile,model,token=None):\n",
    "    slices = dask.array.core.slices_from_chunks(dask.array.empty(tile.shape).chunks)\n",
    "    out = np.empty(shape=tile.shape[2:], dtype=\"uint8\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    A = torch.as_tensor(tile[0][np.newaxis, ...]) #gpu_chip = torch.as_tensor(tile[slice_][np.newaxis, ...]).to(device)\n",
    "    B = torch.as_tensor(tile[1][np.newaxis, ...])\n",
    "    gpu_chip = {'name':'test','A':A.float().to(device),'B':B.float().to(device),'L':torch.zeros(1,1,256,256).float().to(device)}\n",
    "    out = predict_chips(gpu_chip, model)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e4bd7-9e4d-49e4-a3dd-fa7a0f9c2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = np.array([[]], dtype=\"uint8\")[:0]\n",
    "\n",
    "predictions_array = ds_comb.data.map_blocks(\n",
    "    copy_and_predict_chunked,\n",
    "    meta=meta,\n",
    "    drop_axis=[0,1],\n",
    "    model=remote_model,\n",
    "    name=\"predict\",\n",
    ")\n",
    "\n",
    "predictions_array\n",
    "\n",
    "predictions = xr.DataArray(\n",
    "    predictions_array,\n",
    "    coords=ds_comb.drop_vars(\"band\").coords,\n",
    "    dims=(\"y\", \"x\"),\n",
    ")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f2c0b-fbc6-4dd0-8842-4d6e79f8ca55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = predictions.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33842fd-979a-4263-9ab3-aaa5bba137b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "from bokeh.models.tools import BoxZoomTool\n",
    "import panel\n",
    "import hvplot.xarray\n",
    "\n",
    "def logo(plot, element):\n",
    "    plot.state.toolbar.logo = None\n",
    "\n",
    "\n",
    "zoom = BoxZoomTool(match_aspect=True)\n",
    "style_kwargs = dict(\n",
    "    width=450,\n",
    "    height=400,\n",
    "    xaxis=False,\n",
    "    yaxis=False,\n",
    ")\n",
    "kwargs = dict(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    rasterize=True,\n",
    "    cmap='gray',\n",
    "    aggregator=\"mode\",\n",
    "    colorbar=False,\n",
    "    tools=[\"pan\", zoom, \"wheel_zoom\", \"reset\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ddb31-8a8f-4165-898a-fd130ffc4947",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = ds.shape[2] // 2, ds.shape[3] // 2\n",
    "slice_y = slice(middle[0], middle[0] + 5_000)\n",
    "slice_x = slice(middle[1], middle[1] + 5_000)\n",
    "\n",
    "parts = [x.isel(y=slice_y, x=slice_x) for x in [ds, predictions, test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f7ab4-9255-4309-8f54-e22fcfcc9816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_local, predictions_local, test_local = dask.compute(*parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81710b-62be-413d-bed9-7c00b6883436",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel.Column(\n",
    "    panel.Row(\n",
    "        ds_local.sel(time=0)\n",
    "        .hvplot.rgb(\n",
    "            bands=\"band\", rasterize=True, hover=False, title=\"Austin 05_21\", tools=[\"pan\", zoom, \"wheel_zoom\", \"reset\"], **style_kwargs\n",
    "        )\n",
    "        .opts(default_tools=[], hooks=[logo]),\n",
    "        test_local\n",
    "        .hvplot.image(title=\"Changes\", **kwargs, **style_kwargs)\n",
    "        .opts(default_tools=[]),\n",
    "        ds_local.sel(time=1)\n",
    "        .hvplot.rgb(\n",
    "            bands=\"band\",\n",
    "            rasterize=True,\n",
    "            hover=False,\n",
    "            title=\"Austin 05_22\",\n",
    "            tools=[\"pan\", zoom, \"wheel_zoom\", \"reset\"],\n",
    "            **style_kwargs,\n",
    "        )\n",
    "        .opts(default_tools=[], hooks=[logo]),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c1b46-f327-4385-b1b4-b26f6a22ce40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39-planet]",
   "language": "python",
   "name": "conda-env-py39-planet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
